{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2a9a77-d667-4891-aa47-dcafb1c948ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.32.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\dell\\anaconda3\\lib\\site-packages (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5b0e866-a154-4e5e-9281-57548400dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Example HTML content\n",
    "html_content = \"<html><span id='productTitle'>Sample Title</span></html>\"\n",
    "\n",
    "# Initialize BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c05fb51a-77c7-4180-8d40-011ec6b8dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "842dc320-2d3c-43aa-b048-47c8e9fbaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_details(product_url: str) -> dict:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "685d324d-b0ad-4e1c-9f28-38630c3460be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_details(product_url: str) -> dict:\n",
    "  # Create an empty product details dictionary\n",
    "  product_details = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c4410bff-ebaa-472b-8f57-4db19e945a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_details(product_url: str) -> dict:\n",
    "  # Create an empty product details dictionary\n",
    "  product_details = {}\n",
    "\n",
    "  # Get the product page content and create a soup\n",
    "  page = requests.get(product_url, headers=headers)\n",
    "  soup = BeautifulSoup(page.content, features='lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c8c55ab-7b8e-4153-a603-677f84965c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Title\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('span', attrs={'id': 'productTitle'}).get_text().strip()\n",
    "print(title)  # Output: Sample Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5519b45-0d8e-41ba-9234-7dbc4c256ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "print(type(BeautifulSoup))  # Should output: <class 'bs4.BeautifulSoup'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b346f0d-64a7-4a3a-914e-c728539345dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <span id=\"productTitle\">\n",
      "  Sample Title\n",
      " </span>\n",
      "</html>\n",
      "\n",
      "Price element not found\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())\n",
    "price_element = soup.find('span', attrs={'class': 'a-price'})\n",
    "if price_element:\n",
    "    price = price_element.get_text().strip()\n",
    "    print(price)\n",
    "else:\n",
    "    print(\"Price element not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f74c5508-0436-4826-a53f-79bea9e9952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price element not found\n"
     ]
    }
   ],
   "source": [
    "price_element = soup.find('span', class_='a-price')  # Alternative syntax\n",
    "price_element = soup.select_one('span.a-price')  # CSS selector for elements with class 'a-price'\n",
    "if price_element:\n",
    "    price = price_element.get_text().strip()\n",
    "    print(price)\n",
    "else:\n",
    "    print(\"Price element not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9740b71e-e784-4f06-b397-f2134b129347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price element not found\n",
      "<html>\n",
      " <span id=\"productTitle\">\n",
      "  Sample Title\n",
      " </span>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_element = soup.find('span', attrs={'class': 'a-price'})\n",
    "if price_element:\n",
    "    extracted_price = price_element.get_text().strip()\n",
    "    price = '$' + extracted_price.split('$')[1]\n",
    "    print(price)\n",
    "else:\n",
    "    print(\"Price element not found\")\n",
    "\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69896428-db71-4f37-86da-88bea60ac196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Sample Title', 'price': 'Price not found'}\n"
     ]
    }
   ],
   "source": [
    "product_details = {}\n",
    "\n",
    "# Check if 'title' and 'price' are extracted correctly before adding to the dictionary\n",
    "if title:\n",
    "    product_details['title'] = title\n",
    "else:\n",
    "    product_details['title'] = \"Title not found\"\n",
    "\n",
    "if price_element:\n",
    "    product_details['price'] = price\n",
    "else:\n",
    "    product_details['price'] = \"Price not found\"\n",
    "\n",
    "# Print the product details dictionary\n",
    "print(product_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db788fdd-0cb0-4787-b0fb-d77fbb0f2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_details(product_url: str) -> dict:\n",
    "  # Create an empty product details dictionary\n",
    "  product_details = {}\n",
    "\n",
    "  # Get the product page content and create a soup\n",
    "  page = requests.get(product_url, headers=headers)\n",
    "  soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "  try:\n",
    "    # Scrape the product details\n",
    "    title = soup.find('span', attrs={'id': 'productTitle'}).get_text().strip()\n",
    "    extracted_price = soup.find('span', attrs={'class': 'a-price'}).get_text().strip()\n",
    "    price = extracted_price.split('$')[1]\n",
    "\n",
    "    # Adding it to the product details dictionary\n",
    "    product_details['title'] = title\n",
    "    product_details['price'] = price\n",
    "    product_details['product_url'] = product_url\n",
    "\n",
    "    # Return the product details dictionary\n",
    "    return product_details\n",
    "  except Exception as e:\n",
    "    print('Could not fetch product details')\n",
    "    print(f'Failed with exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c74c0d03-34ee-4cd8-bce3-499b8e0689ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'BLINKIN Soft Touch Thermal Skinny Tights For Women - Ultimate Warm Fleece Leggings For Women, Thermal Winter Tights, Free Size (26Inch Waist To 34Inch)', 'price': '389'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Input the product URL\n",
    "product_url = \"https://www.amazon.in/BLINKIN-Velvet-Touch-Thermal-Tights/dp/B0DF2WPXV2/ref=zg_bs_c_apparel_d_sccl_1/262-7759192-7171239?pd_rd_w=ZM3kC&content-id=amzn1.sym.cde02f8b-0594-439d-9e93-f4cced7ce3ce&pf_rd_p=cde02f8b-0594-439d-9e93-f4cced7ce3ce&pf_rd_r=7DWPTFYJQQ9FRH8XZ7G5&pd_rd_wg=SOZM6&pd_rd_r=14b4a8e0-fa8d-4eb0-aeeb-0f0cdc5f1cfd&pd_rd_i=B0DF2WPXV2&psc=1\"\n",
    "\n",
    "try:\n",
    "    # Fetch the page content\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    response = requests.get(product_url, headers=headers)\n",
    "    response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the product title\n",
    "    title_element = soup.find('span', attrs={'id': 'productTitle'})\n",
    "    title = title_element.get_text().strip() if title_element else \"Title not found\"\n",
    "\n",
    "    # Extract the product price\n",
    "    price_element = soup.find('span', attrs={'class': 'a-price-whole'})\n",
    "    price = price_element.get_text().strip() if price_element else \"Price not found\"\n",
    "\n",
    "    # Display the product details\n",
    "    product_details = {'title': title, 'price': price}\n",
    "    print(product_details)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to fetch product details. Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed with exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfe61c-b793-42e5-8707-1ffa90e33215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
